{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An Introduction to Keras\n",
    "In this notebook, I will provide a brief introduction to [Keras](https://keras.io/), a high-level neural networks python library; it is a wrapper ontop of either **Theano** or **Tensorflow**. \n",
    "\n",
    "In the first part, I will implement the simple perceptron model from the first homework. Then I will try the 'hello world' of neural net applications: hand-writing recognition from the [MNIST database](http://yann.lecun.com/exdb/mnist/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST Database\n",
    "The MNIST database of handwritten digits. It consists of a training set of **60,000 examples**, and a test set of **10,000 examples**. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n",
    "\n",
    "It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.\n",
    "\n",
    "*From [Yann Lecun's Website](http://yann.lecun.com/exdb/mnist/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import the necessary basic python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named seaborn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0bc9ca8f540a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ticks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named seaborn"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Standard Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='ticks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we let's load the **MNIST dataset**. Fortunately for us, this is already available in the **Keras** module (as well as many other common datasets). So we will import from **Keras** as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11345920/11490434 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAEZCAYAAABM/vhsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9690526350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Dataset from Keras Libraries\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "nb_class = 10\n",
    "\n",
    "# Visualize Some Examples\n",
    "idx = np.random.choice(X_train.shape[0],6,replace=False)\n",
    "for i,ix in enumerate(idx):\n",
    "    plt.subplot(231+i)\n",
    "    plt.title('Label is {0}'.format(y_train[ix]))\n",
    "    plt.imshow(X_train[ix], cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Reshape X data from 2D to 1D (28x28 to 784)\n",
    "X_train = X_train.reshape(60000,784).astype('float32')\n",
    "X_test  = X_test.reshape(10000,784).astype('float32')\n",
    "\n",
    "# Convert Y labels to Categorical One-Hot Format\n",
    "y_train = np_utils.to_categorical(y_train, nb_class)\n",
    "y_test = np_utils.to_categorical(y_test, nb_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model\n",
    "Now, we are goint to create our neural network model using Keras' high-level library. The big advantage of Keras is that it abstracts away the low level code of the basic elements of neural networks such as hidden units, layers, activations, optimizers, etc. In other words, you just call Keras functions to create these things for you, without hand coding the details yourself. Underneath it all, Keras is using **Tensorflow** or **Theano**, just like you would yourself.\n",
    "\n",
    "To demonstrate this, let's first decide on a network architecture for our MNIST dataset. Let's use the same architecture as in the `multilayer_perceptron.py` example we used in class to test our **Tensorflow** installation. Here is the network architecture:\n",
    "\n",
    "#### Network Architecture\n",
    "![Network Architecture](NetArch1.png)\n",
    "\n",
    "Now let's proceed to build this in Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Keras Libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "\n",
    "# Define Model Parameters\n",
    "nb_feat   = 28    # no. of features/columns of input\n",
    "L1_units  = 256   # no. of nodes in Layer 1\n",
    "L2_units  = 100   # no. of nodes in Layer 2\n",
    "L3_units  = 50   # no. of nodes in Layer 2\n",
    "nb_class  = 10    # no. of output classes\n",
    "\n",
    "# Neural Network Model\n",
    "model = Sequential()                             # Sequential network model description\n",
    "model.add(Dense(L1_units,input_shape=(784,)))    # Add 1st Dense Layer\n",
    "model.add(Activation(\"relu\"))                    # Add activation function\n",
    "\n",
    "model.add(Dense(L2_units))                       # Add 2nd Dense Layer\n",
    "model.add(Activation(\"relu\"))                    # Add activation function\n",
    "\n",
    "model.add(Dense(L3_units))                       # Add 3nd Dense Layer\n",
    "model.add(Activation(\"relu\"))                    # Add activation function\n",
    "\n",
    "model.add(Dense(nb_class))                       # Add 3rd Dense Layer, also the classification layer\n",
    "model.add(Activation('softmax'))                 # Add sigmoid classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've described the model in a sequential model, you then proceed to compile the model. The model needs to be compiled because the actual Theano/Tensorflow backend uses C/C++ internally for faster implementations and runs. \n",
    "\n",
    "Also, while compiling, we defining the loss function (optimization criterion) and the kind of optimizer to use. Here I use the popular **RMSprop**, an adaptive variant of gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I proceed to train the model with a simple one line command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "12s - loss: 9.8638 - acc: 0.3864 - val_loss: 8.7378 - val_acc: 0.4571\n",
      "Epoch 2/30\n",
      "12s - loss: 8.7325 - acc: 0.4574 - val_loss: 8.5636 - val_acc: 0.4682\n",
      "Epoch 3/30\n",
      "12s - loss: 8.5586 - acc: 0.4686 - val_loss: 8.5682 - val_acc: 0.4681\n",
      "Epoch 4/30\n",
      "12s - loss: 8.5785 - acc: 0.4674 - val_loss: 8.4555 - val_acc: 0.4751\n",
      "Epoch 5/30\n",
      "15s - loss: 8.5295 - acc: 0.4704 - val_loss: 8.4599 - val_acc: 0.4746\n",
      "Epoch 6/30\n",
      "15s - loss: 8.4660 - acc: 0.4744 - val_loss: 8.7201 - val_acc: 0.4586\n",
      "Epoch 7/30\n",
      "12s - loss: 8.4377 - acc: 0.4763 - val_loss: 8.4889 - val_acc: 0.4730\n",
      "Epoch 8/30\n",
      "13s - loss: 8.4451 - acc: 0.4758 - val_loss: 8.4055 - val_acc: 0.4783\n",
      "Epoch 9/30\n",
      "12s - loss: 8.4453 - acc: 0.4759 - val_loss: 8.4317 - val_acc: 0.4767\n",
      "Epoch 10/30\n",
      "12s - loss: 8.4305 - acc: 0.4768 - val_loss: 8.4400 - val_acc: 0.4761\n",
      "Epoch 11/30\n",
      "12s - loss: 8.4669 - acc: 0.4745 - val_loss: 8.5217 - val_acc: 0.4712\n",
      "Epoch 12/30\n",
      "18s - loss: 8.4461 - acc: 0.4758 - val_loss: 8.2971 - val_acc: 0.4850\n",
      "Epoch 13/30\n",
      "16s - loss: 8.3920 - acc: 0.4792 - val_loss: 8.4626 - val_acc: 0.4747\n",
      "Epoch 14/30\n",
      "13s - loss: 8.4139 - acc: 0.4778 - val_loss: 8.3936 - val_acc: 0.4790\n",
      "Epoch 15/30\n",
      "12s - loss: 8.3682 - acc: 0.4807 - val_loss: 8.2862 - val_acc: 0.4857\n",
      "Epoch 16/30\n",
      "12s - loss: 8.3724 - acc: 0.4804 - val_loss: 8.4008 - val_acc: 0.4788\n",
      "Epoch 17/30\n",
      "12s - loss: 8.4060 - acc: 0.4783 - val_loss: 8.3652 - val_acc: 0.4809\n",
      "Epoch 18/30\n",
      "12s - loss: 8.4168 - acc: 0.4776 - val_loss: 8.3508 - val_acc: 0.4818\n",
      "Epoch 19/30\n",
      "20s - loss: 8.4517 - acc: 0.4754 - val_loss: 8.3273 - val_acc: 0.4832\n",
      "Epoch 20/30\n",
      "17s - loss: 8.3952 - acc: 0.4790 - val_loss: 8.3369 - val_acc: 0.4826\n",
      "Epoch 21/30\n",
      "12s - loss: 8.4348 - acc: 0.4765 - val_loss: 8.6881 - val_acc: 0.4607\n",
      "Epoch 22/30\n",
      "12s - loss: 8.3758 - acc: 0.4802 - val_loss: 8.2882 - val_acc: 0.4856\n",
      "Epoch 23/30\n",
      "14s - loss: 8.3285 - acc: 0.4832 - val_loss: 8.4475 - val_acc: 0.4757\n",
      "Epoch 24/30\n",
      "12s - loss: 8.3776 - acc: 0.4801 - val_loss: 8.2869 - val_acc: 0.4858\n",
      "Epoch 25/30\n",
      "14s - loss: 8.3550 - acc: 0.4815 - val_loss: 8.2612 - val_acc: 0.4873\n",
      "Epoch 26/30\n",
      "12s - loss: 8.3403 - acc: 0.4824 - val_loss: 8.3634 - val_acc: 0.4809\n",
      "Epoch 27/30\n",
      "14s - loss: 8.3340 - acc: 0.4828 - val_loss: 8.2622 - val_acc: 0.4873\n",
      "Epoch 28/30\n",
      "11s - loss: 8.3116 - acc: 0.4842 - val_loss: 8.3776 - val_acc: 0.4800\n",
      "Epoch 29/30\n",
      "11s - loss: 8.3296 - acc: 0.4831 - val_loss: 8.3114 - val_acc: 0.4842\n",
      "Epoch 30/30\n",
      "11s - loss: 8.3569 - acc: 0.4814 - val_loss: 8.2607 - val_acc: 0.4874\n"
     ]
    }
   ],
   "source": [
    "log = model.fit(X_train, y_train,nb_epoch=30, batch_size=32, verbose=2,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-Learn Machine Learning Utilities\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "## Final Accuracy\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print'Model Accuracy: {}%'.format(score[1]*100)\n",
    "print ''\n",
    "print ''\n",
    "\n",
    "y_pred = model.predict_classes(X_test)\n",
    "cm = confusion_matrix(np.argmax(y_test,axis=1),y_pred)  ## Confusion matrix\n",
    "plot_confusion_matrix(cm, ['0','1','2','3','4','5','6','7','8','9'],normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(log.history['acc'])\n",
    "plt.plot(log.history['val_acc'])\n",
    "plt.title('Model Accuracy'), plt.ylabel('Accuracy'), plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(log.history['loss'])\n",
    "plt.plot(log.history['val_loss'])\n",
    "plt.title('Model Loss'), plt.ylabel('Loss'), plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
